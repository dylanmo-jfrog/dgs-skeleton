name: "Build and Publish DGS"
on: 
  workflow_dispatch: # manual trigger
    inputs:
      deploy_to_eks:
        description: 'Deploy to EKS?'
        type: choice
        options:
          - 'yes'
          - 'no'
        required: true
        default: 'no'
  push:
    branches:
      - main
    paths:
      - '**.java'
      - 'pom.xml'

jobs:
  build:
    runs-on: ubuntu-latest

    # Setup environment variables, some of them can be overridden by repository variables
    permissions:
      id-token: write
      contents: write
      pull-requests: write
      security-events: write
      actions: read 
      attestations: write    
      packages: write    
    env:
      JF_HOST: ${{ vars.JF_HOST                 || 'soleng.jfrog.io' }}
      JF_PROJECT_KEY: ${{ vars.JF_PROJECT_KEY   || 'dmodgs' }}
      BUILD_NAME: ${{ vars.BUILD_NAME           || 'dylanmo-dgs-docker-build' }}
      BUILD_NUMBER: ${{ vars.BUILD_NUMBER       || github.run_id }}
      DOCKER_REPO: 'dylanmo-dev-docker-local'
      IMAGE_NAME: 'graphql-dgs-tcat'
      MVN_VIRTUAL_REPO_SNAPSHOT: 'dylanmo-dev-libs-snapshot'
      MVN_VIRTUAL_REPO_RELEASE: 'dylanmo-dev-libs-release'

    # Here we install all the tools : docker buildx, QEMU, JDK 11, JFrog CLI
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Set up JDK 11
        uses: actions/setup-java@v3
        with:
          java-version: '11'
          distribution: 'corretto'        
          cache: 'maven'
    
    # Install JFrog CLI using the JFrog CLI GitHub Action      
      - name: Setup JFrog CLI
        id: setup-cli
        uses: jfrog/setup-jfrog-cli@v4
        env:
          JF_URL: https://${{ env.JF_HOST }}/
          JF_PROJECT: ${{ env.JF_PROJECT_KEY }}
          # Override any automatic build number with our desired one
          JFROG_CLI_BUILD_NAME: ${{ env.BUILD_NAME }}
          JFROG_CLI_BUILD_NUMBER: ${{ env.BUILD_NUMBER }}
        with:
            oidc-provider-name: dylanmo-github
            oidc-audience: dylanmo-github

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
     
      # We build & test the WAR file, scan it and if scan result ok, we publish it to our artifactory maven repository
      - name: Run Maven build
        id: build 
        env:
          PKG_VERSION: 1.${{ env.BUILD_NUMBER }}.0
          JF_PROJECT: ${{ env.JF_PROJECT_KEY }}
        run: |
            # Collect environment variables for the build
            jf rt bce ${{ env.BUILD_NAME }} ${{ env.BUILD_NUMBER }} 
            jf mvnc --repo-resolve-releases=${{ env.MVN_VIRTUAL_REPO_RELEASE }} \
              --repo-deploy-releases=${{ env.MVN_VIRTUAL_REPO_RELEASE }} \
              --repo-resolve-snapshots=${{ env.MVN_VIRTUAL_REPO_SNAPSHOT }} \
              --repo-deploy-snapshots=${{ env.MVN_VIRTUAL_REPO_SNAPSHOT }}

            # Run curation audit and print output to log
            audit_output=$(jf ca 2>&1)

            # Check if blocked packages were found
            if echo "$audit_output" | grep -q "Found [1-9][0-9]* blocked packages"; then
              echo "::error::Curation audit detected blocked packages - failing build"
              echo "curation_failed=true" >> $GITHUB_OUTPUT
              exit 1
            fi

            jf rt bag ${{ env.BUILD_NAME }} ${{ env.BUILD_NUMBER }} # collect vcs info
            jf mvn -f pom.xml -Drevision=${{ env.PKG_VERSION }} -Dmaven.test.skip=true clean package # build the war
            jf audit --mvn --fail=false --vuln # scan the war
            jf mvn -f pom.xml -Drevision=${{ env.PKG_VERSION }} -Dmaven.test.skip=true --build-name=${{ env.BUILD_NAME }} --build-number=${{ env.BUILD_NUMBER }} deploy # deploy the war
            jf rt bp ${{ env.BUILD_NAME }} ${{ env.BUILD_NUMBER }} # publish the build info
            jf bs --fail=false --vuln ${{ env.BUILD_NAME }} ${{ env.BUILD_NUMBER }}
            
            # Debug: List files in target directory
            echo "Listing files in target directory:"
            ls -la target/
            
            # Debug: Check if WAR file exists with exact name
            echo "Checking for WAR file:"
            ls -la target/dgs-skeleton-webapp-${{ env.PKG_VERSION }}.war || echo "WAR file not found!"

     # If the curation audit failed, we skip the docker build and push steps       
      - name: Authenticate Docker
        if: steps.build.outputs.curation_failed != 'true'
        uses: docker/login-action@v3
        with:
          registry: ${{ env.JF_HOST }}
          username: ${{ steps.setup-cli.outputs.oidc-user }}
          password: ${{ steps.setup-cli.outputs.oidc-token }}
                
      - name: Build and push docker tomcat + war based docker images
        if: steps.build.outputs.curation_failed != 'true'
        env: 
          PKG_VERSION: 1.${{ env.BUILD_NUMBER }}.0
          JF_PROJECT: ${{ env.JF_PROJECT_KEY }}
        uses: docker/build-push-action@v6
        id: docker_build
        with:
          context: .
          platforms: linux/amd64,linux/arm64
          provenance: true
          push: true
          build-args: |
            WAR_FILE_NAME=dgs-skeleton-webapp-${{ env.PKG_VERSION }}.war
          tags: ${{ env.JF_HOST }}/${{ env.DOCKER_REPO }}/${{ env.IMAGE_NAME}}:${{ env.PKG_VERSION }}
      
      - name: Push Docker build info
        env:
          PKG_VERSION: 1.${{ env.BUILD_NUMBER }}.0
          JF_PROJECT: ${{ env.JF_PROJECT_KEY }}
        run: |
          echo ${{ env.JF_HOST }}/${{ env.DOCKER_REPO }}/${{ env.IMAGE_NAME}}:${{ env.PKG_VERSION }}@${{ steps.docker_build.outputs.digest }} > ./image-metadata.json
          # Collect environment variables for the build
          jf rt bce ${{ env.BUILD_NAME }} ${{ env.BUILD_NUMBER }} 
          # collect vcs info
          jf rt bag ${{ env.BUILD_NAME }} ${{ env.BUILD_NUMBER }}
          # As the docker images have been built by buildx, we don't have them locally, 
          # so we link the build info to the already published images in previous steps
          jf rt bdc ${{ env.DOCKER_REPO }} --image-file ./image-metadata.json --build-name ${{ env.BUILD_NAME }} --build-number ${{ env.BUILD_NUMBER }}
          # Publish build info
          jf rt bp ${{ env.BUILD_NAME }} ${{ env.BUILD_NUMBER }}

      - name: Scan the build & the docker image
        env:
          PKG_VERSION: 1.${{ env.BUILD_NUMBER }}.0
          JF_PROJECT: ${{ env.JF_PROJECT_KEY }}
        run: |
          # Xray build scan example
          docker pull ${{ env.JF_HOST }}/${{ env.DOCKER_REPO }}/${{ env.IMAGE_NAME}}:${{ env.PKG_VERSION }}
          jf docker scan ${{ env.JF_HOST }}/${{ env.DOCKER_REPO }}/${{ env.IMAGE_NAME}}:${{ env.PKG_VERSION }} --severity='HIGH,CRITICAL' --vuln
          jf bs --fail=false --vuln ${{ env.BUILD_NAME }} ${{ env.BUILD_NUMBER }}

  deploy-to-eks:
    needs: build
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.deploy_to_eks == 'yes'
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
      pull-requests: read

    env:
      AWS_REGION: us-east-1
      EKS_CLUSTER_NAME: dgs-skeleton-cluster
      JF_HOST: ${{ vars.JF_HOST || 'soleng.jfrog.io' }}
      JF_PROJECT_KEY: ${{ vars.JF_PROJECT_KEY || 'dmodgs' }}
      BUILD_NUMBER: ${{ vars.BUILD_NUMBER || github.run_id }}
      DOCKER_REPO: 'dylanmo-dev-docker-local'
      IMAGE_NAME: 'graphql-dgs-tcat'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup JFrog CLI
      id: setup-cli
      uses: jfrog/setup-jfrog-cli@v4
      env:
        JF_URL: https://${{ env.JF_HOST }}/
        JF_PROJECT: ${{ env.JF_PROJECT_KEY }}
      with:
        oidc-provider-name: dylanmo-github
        oidc-audience: dylanmo-github

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: 1.5.0

    - name: Setup Backend Infrastructure
      working-directory: ./terraform/bootstrap
      run: |
        terraform init
        
        # Try to import existing S3 bucket
        terraform import aws_s3_bucket.terraform_state dgs-skeleton-terraform-state || true
        
        # Apply changes (this will update any configuration if needed)
        terraform apply -auto-approve

    - name: Terraform Init
      working-directory: ./terraform
      run: terraform init

    - name: Terraform Apply
      working-directory: ./terraform
      run: terraform apply -auto-approve

    - name: Update kube config
      run: aws eks update-kubeconfig --name $EKS_CLUSTER_NAME --region ${{ env.AWS_REGION }}

    - name: Deploy to EKS
      env:
        PKG_VERSION: 1.${{ env.BUILD_NUMBER }}.0
      run: |
        # Replace the image reference in the deployment file with the Artifactory image
        FULL_IMAGE_NAME="${{ env.JF_HOST }}/${{ env.DOCKER_REPO }}/${{ env.IMAGE_NAME }}:${{ env.PKG_VERSION }}"
        sed -i "s|image: CONTAINER_IMAGE|image: ${FULL_IMAGE_NAME}|" k8s/deployment.yaml
        
        # Create image pull secret for Artifactory using OIDC token
        kubectl create secret docker-registry artifactory-pull-secret \
          --docker-server=${{ env.JF_HOST }} \
          --docker-username=${{ steps.setup-cli.outputs.oidc-user }} \
          --docker-password=${{ steps.setup-cli.outputs.oidc-token }} \
          --dry-run=client -o yaml | kubectl apply -f -
        
        # Apply the deployment
        kubectl apply -f k8s/deployment.yaml
        
        # Wait for deployment to be ready
        kubectl rollout status deployment/dgs-skeleton --timeout=300s